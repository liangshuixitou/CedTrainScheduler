{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"./ali-cluster/cluster-trace-gpu-v2020/data\"\n",
    "\n",
    "def read_csv_with_header(\n",
    "    file_path: str,\n",
    "    header: Optional[list[str]] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"读取 CSV 文件并处理表头\n",
    "\n",
    "    Args:\n",
    "        file_path: CSV 文件路径\n",
    "        header: 可选的表头列表。如果为 None, 则从对应的 .header 文件读取\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 读取并设置好表头的数据框\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: 当 CSV 文件或对应的 header 文件不存在时\n",
    "        pd.errors.EmptyDataError: 当 CSV 文件为空时\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path, header=None)\n",
    "    df.columns = (pd.read_csv(\"{}.header\".format(file_path.split('.csv')[0])).columns\n",
    "                 if header is None else header)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_configs():\n",
    "    \"\"\"获取预定义的模型配置\"\"\"\n",
    "    return [\n",
    "        {\n",
    "            'model_name': 'ResNet50',\n",
    "            'task_type': 'Image Classification',\n",
    "            'batch_sizes': [32, 64, 128],\n",
    "            'dataset_name': 'ImageNet',\n",
    "            'dataset_size': 150000,  # ImageNet原始数据集约150GB\n",
    "            'model_size': 98  # ResNet50标准模型大小约98MB\n",
    "        },\n",
    "        {\n",
    "            'model_name': 'MobileNetV3',\n",
    "            'task_type': 'Image Classification', \n",
    "            'batch_sizes': [32, 64, 128],\n",
    "            'dataset_name': 'ImageNet',\n",
    "            'dataset_size': 150000,\n",
    "            'model_size': 22  # MobileNetV3轻量化模型典型大小\n",
    "        },\n",
    "        {\n",
    "            'model_name': 'ResNet18',\n",
    "            'task_type': 'Image Classification',\n",
    "            'batch_sizes': [32, 64, 128],\n",
    "            'dataset_name': 'CIFAR-10',\n",
    "            'dataset_size': 170,  # CIFAR-10压缩包标准大小约170MB\n",
    "            'model_size': 45  # ResNet18典型参数量对应约45MB\n",
    "        },\n",
    "        {\n",
    "            'model_name': 'MobileNetV2',\n",
    "            'task_type': 'Image Classification',\n",
    "            'batch_sizes': [32, 64, 128],\n",
    "            'dataset_name': 'CIFAR-10',\n",
    "            'dataset_size': 170,\n",
    "            'model_size': 14  # MobileNetV2轻量化版本典型大小\n",
    "        },\n",
    "        {\n",
    "            'model_name': 'EfficientNet',\n",
    "            'task_type': 'Image Classification',\n",
    "            'batch_sizes': [32, 64, 128],\n",
    "            'dataset_name': 'CIFAR-10',\n",
    "            'dataset_size': 170,\n",
    "            'model_size': 29  # EfficientNet-B0基准模型大小\n",
    "        },\n",
    "        {\n",
    "            'model_name': 'VGG11',\n",
    "            'task_type': 'Image Classification',\n",
    "            'batch_sizes': [32, 64, 128],\n",
    "            'dataset_name': 'CIFAR-10',\n",
    "            'dataset_size': 170,\n",
    "            'model_size': 507  # VGG11典型参数量对应约507MB\n",
    "        },\n",
    "        {\n",
    "            'model_name': 'DCGAN',\n",
    "            'task_type': 'Image Generation',\n",
    "            'batch_sizes': [64, 128, 256],\n",
    "            'dataset_name': 'LSUN',\n",
    "            'dataset_size': 42000,  # LSUN官方发布版本约42GB\n",
    "            'model_size': 45  # DCGAN基础架构典型模型大小\n",
    "        },\n",
    "        {\n",
    "            'model_name': 'PointNet',\n",
    "            'task_type': '3D Point Cloud Processing',\n",
    "            'batch_sizes': [32, 64, 128],\n",
    "            'dataset_name': 'ShapeNet',\n",
    "            'dataset_size': 30000,  # ShapeNet Core55版本约30GB\n",
    "            'model_size': 40  # PointNet基础模型参数量对应约40MB\n",
    "        },\n",
    "        {\n",
    "            'model_name': 'BERT',\n",
    "            'task_type': 'Question Answering',\n",
    "            'batch_sizes': [32],\n",
    "            'dataset_name': 'SQuAD',\n",
    "            'dataset_size': 35000,  # SQuAD v2.0预处理后约35GB\n",
    "            'model_size': 1200  # BERT-Base英文版约1.2GB\n",
    "        },\n",
    "        {\n",
    "            'model_name': 'LSTM',\n",
    "            'task_type': 'Language Modeling',\n",
    "            'batch_sizes': [32, 64, 128],\n",
    "            'dataset_name': 'Wikitext2',\n",
    "            'dataset_size': 5000,  # Wikitext2原始文本约5GB\n",
    "            'model_size': 35  # 单层LSTM典型参数量对应约35MB\n",
    "        },\n",
    "        {\n",
    "            'model_name': 'Transformer',\n",
    "            'task_type': 'Machine Translation',\n",
    "            'batch_sizes': [16, 32, 64],\n",
    "            'dataset_name': 'Multi30k',\n",
    "            'dataset_size': 3000,  # Multi30k标准版本约3GB\n",
    "            'model_size': 85  # 基础Transformer模型参数量对应约85MB\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_training_data(task_df) -> pd.DataFrame:\n",
    "    \"\"\"数据预处理：筛选和清理训练任务数据\n",
    "\n",
    "    对原始任务数据进行预处理，包括：\n",
    "    1. 合并任务和作业数据\n",
    "    2. 清理无效时间戳\n",
    "    3. 筛选有效训练任务\n",
    "    4. 标准化时间\n",
    "    5. 统一GPU类型\n",
    "\n",
    "    Args:\n",
    "        task_df: 任务数据表\n",
    "        job_df: 作业数据表\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: 处理后的训练任务数据，包含以下主要字段：\n",
    "            - job_name: 作业名称\n",
    "            - gpu_type: GPU类型(V100或T4)\n",
    "            - runtime: 运行时长\n",
    "            - norm_job_submit_time: 标准化后的作业提交时间\n",
    "    \"\"\"\n",
    "    # 常量定义\n",
    "    MIN_RUNTIME_SECONDS = 1000.0  # 最小运行时间（秒）\n",
    "    VALID_TASK_TYPES = ['tensorflow', 'PyTorchWorker', 'worker']\n",
    "\n",
    "\n",
    "    # 处理无效的时间戳\n",
    "    task_df.loc[task_df.start_time == 0, ['start_time', 'end_time']] = np.nan\n",
    "    task_df['runtime'] = task_df.end_time - task_df.start_time\n",
    "\n",
    "    # 筛选有效的训练任务\n",
    "    valid_tasks = task_df[\n",
    "        (task_df['status'] == 'Terminated') &             # 已完成的任务\n",
    "        (task_df['gpu_type'] != 'MISC') &                 # 排除杂项GPU类型\n",
    "        (task_df['plan_gpu'] == 100) &                    # 完整GPU使用\n",
    "        (task_df['runtime'] >= MIN_RUNTIME_SECONDS) &     # 运行时间足够长\n",
    "        (task_df['inst_num'] <= 8) &                     # 实例数量小于8\n",
    "        (task_df['task_name'].isin(VALID_TASK_TYPES))     # 有效的任务类型\n",
    "    ]\n",
    "\n",
    "    # 按提交时间排序并标准化\n",
    "    valid_tasks = valid_tasks.sort_values(['start_time'])\n",
    "\n",
    "    # 去重并统一GPU类型名称\n",
    "    valid_tasks.loc[valid_tasks.gpu_type == 'V100M32', 'gpu_type'] = 'V100'\n",
    "\n",
    "    return valid_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def sample_tasks_random(task_df: pd.DataFrame, jobs_count: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    从任务数据中纯随机采样指定数量的任务\n",
    "\n",
    "    Args:\n",
    "        task_df: 任务数据表\n",
    "        jobs_count: 需要采样的任务总数量\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 随机采样后的任务数据表\n",
    "    \"\"\"\n",
    "    # 确保采样数量不超过可用数据量\n",
    "    sample_size = min(jobs_count, len(task_df))\n",
    "\n",
    "    # 直接随机采样\n",
    "    sampled_tasks = task_df.sample(n=sample_size)\n",
    "\n",
    "    # 统计采样结果\n",
    "    single_gpu_count = len(sampled_tasks[sampled_tasks['inst_num'] == 1])\n",
    "    multi_gpu_count = len(sampled_tasks[sampled_tasks['inst_num'] > 1])\n",
    "\n",
    "    # 打印采样统计信息\n",
    "    print(f\"采样统计: 总任务数 {len(sampled_tasks)}, \"\n",
    "          f\"单卡任务 {single_gpu_count} ({single_gpu_count/len(sampled_tasks):.1%}), \"\n",
    "          f\"多卡任务 {multi_gpu_count} ({multi_gpu_count/len(sampled_tasks):.1%})\")\n",
    "\n",
    "    return sampled_tasks\n",
    "\n",
    "def sample_tasks_with_ratio(task_df: pd.DataFrame, jobs_count: int, multi_gpu_ratio: float = 0.5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    从任务数据中采样指定数量的任务，并提高多卡任务的比例\n",
    "\n",
    "    Args:\n",
    "        task_df: 任务数据表\n",
    "        jobs_count: 采样任务总数量\n",
    "        multi_gpu_ratio: 多卡任务在采样中的目标比例，默认为0.5\n",
    "    Returns:\n",
    "        pd.DataFrame: 采样后的任务数据表，多卡任务比例提高\n",
    "    \"\"\"\n",
    "    # 将任务分为单卡和多卡两组\n",
    "    single_gpu_tasks = task_df[task_df['inst_num'] == 1]\n",
    "    multi_gpu_tasks = task_df[task_df['inst_num'] > 1]\n",
    "\n",
    "    # 计算需要的多卡和单卡任务数量\n",
    "    multi_gpu_count = int(jobs_count * multi_gpu_ratio)\n",
    "    single_gpu_count = jobs_count - multi_gpu_count\n",
    "\n",
    "    # 如果任一组的任务数量不足，调整采样数量\n",
    "    if len(multi_gpu_tasks) < multi_gpu_count:\n",
    "        multi_gpu_count = len(multi_gpu_tasks)\n",
    "        single_gpu_count = jobs_count - multi_gpu_count\n",
    "\n",
    "    if len(single_gpu_tasks) < single_gpu_count:\n",
    "        single_gpu_count = len(single_gpu_tasks)\n",
    "        multi_gpu_count = jobs_count - single_gpu_count\n",
    "\n",
    "    # 分别从两组中采样\n",
    "    sampled_single = single_gpu_tasks.sample(n=single_gpu_count) if single_gpu_count > 0 else pd.DataFrame()\n",
    "    sampled_multi = multi_gpu_tasks.sample(n=multi_gpu_count) if multi_gpu_count > 0 else pd.DataFrame()\n",
    "\n",
    "    # 合并结果\n",
    "    sampled_tasks = pd.concat([sampled_single, sampled_multi])\n",
    "\n",
    "    # 打印采样统计信息\n",
    "    print(f\"采样统计: 总任务数 {len(sampled_tasks)}, 单卡任务 {len(sampled_single)} ({len(sampled_single)/len(sampled_tasks):.1%}), \"\n",
    "          f\"多卡任务 {len(sampled_multi)} ({len(sampled_multi)/len(sampled_tasks):.1%})\")\n",
    "\n",
    "    return sampled_tasks\n",
    "\n",
    "\n",
    "def gen_task_runtimes(task_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"生成不同 GPU 类型的运行时间\"\"\"\n",
    "    t4_performance = 8.1\n",
    "    p100_performance = 9.3\n",
    "    v100_performance = 15.7\n",
    "\n",
    "    runtimes = {\n",
    "        'T4': (1, 1),\n",
    "        'P100': (t4_performance / p100_performance, t4_performance / p100_performance),\n",
    "        'V100': (t4_performance / v100_performance, t4_performance / v100_performance),\n",
    "    }\n",
    "    gpu_types = runtimes.keys()\n",
    "\n",
    "    def gen_runtime(from_gpu, to_gpu, origin_runtime):\n",
    "        if from_gpu == to_gpu:\n",
    "            return origin_runtime\n",
    "        if from_gpu not in gpu_types:\n",
    "            print(\"not in gpu_types:\", from_gpu)\n",
    "        to_rand = random.uniform(*runtimes[to_gpu])\n",
    "        from_rand = random.uniform(*runtimes[from_gpu])\n",
    "        return int(origin_runtime * to_rand / from_rand)\n",
    "\n",
    "    for gpu_type in gpu_types:\n",
    "        task_df[f'runtime_{gpu_type}'] = task_df.apply(\n",
    "            lambda row, gpu_type=gpu_type: gen_runtime(row['gpu_type'], gpu_type, row['runtime']),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "    # 获取模型配置\n",
    "    model_configs = get_model_configs()\n",
    "\n",
    "    # 为每个任务随机分配一个模型\n",
    "    def assign_model(row):\n",
    "        model_config = random.choice(model_configs)\n",
    "        return model_config['model_name']\n",
    "\n",
    "    # 应用模型分配\n",
    "    task_df['task_name'] = task_df.apply(assign_model, axis=1)\n",
    "\n",
    "    return task_df\n",
    "\n",
    "def to_csv(df, name):\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_csv(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "采样统计: 总任务数 1000, 单卡任务 918 (91.8%), 多卡任务 82 (8.2%)\n",
      "采样统计: 总任务数 1000, 单卡任务 900 (90.0%), 多卡任务 100 (10.0%)\n",
      "采样统计: 总任务数 1000, 单卡任务 500 (50.0%), 多卡任务 500 (50.0%)\n",
      "random task num:\n",
      "   inst_num  task_num\n",
      "0       1.0       918\n",
      "1       2.0        12\n",
      "2       3.0         4\n",
      "3       4.0        25\n",
      "4       5.0        17\n",
      "5       6.0         3\n",
      "6       8.0        21\n",
      "light task num:\n",
      "   inst_num  task_num\n",
      "0       1.0       900\n",
      "1       2.0        13\n",
      "2       3.0         6\n",
      "3       4.0        21\n",
      "4       5.0        27\n",
      "5       6.0         4\n",
      "6       8.0        29\n",
      "heavy task num:\n",
      "   inst_num  task_num\n",
      "0       1.0       500\n",
      "1       2.0        99\n",
      "2       3.0        23\n",
      "3       4.0       129\n",
      "4       5.0        93\n",
      "5       6.0        37\n",
      "6       7.0         2\n",
      "7       8.0       117\n",
      "task_file:case_random_1000_tasks.csv generated\n",
      "task_file:case_light_1000_tasks.csv generated\n",
      "task_file:case_heavy_1000_tasks.csv generated\n",
      "采样统计: 总任务数 2000, 单卡任务 1854 (92.7%), 多卡任务 146 (7.3%)\n",
      "采样统计: 总任务数 2000, 单卡任务 1800 (90.0%), 多卡任务 200 (10.0%)\n",
      "采样统计: 总任务数 2000, 单卡任务 1000 (50.0%), 多卡任务 1000 (50.0%)\n",
      "random task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      1854\n",
      "1       2.0        27\n",
      "2       3.0         6\n",
      "3       4.0        33\n",
      "4       5.0        28\n",
      "5       6.0        11\n",
      "6       7.0         1\n",
      "7       8.0        40\n",
      "light task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      1800\n",
      "1       2.0        34\n",
      "2       3.0         8\n",
      "3       4.0        54\n",
      "4       5.0        40\n",
      "5       6.0        17\n",
      "6       8.0        47\n",
      "heavy task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      1000\n",
      "1       2.0       206\n",
      "2       3.0        42\n",
      "3       4.0       238\n",
      "4       5.0       193\n",
      "5       6.0        70\n",
      "6       7.0         6\n",
      "7       8.0       245\n",
      "task_file:case_random_2000_tasks.csv generated\n",
      "task_file:case_light_2000_tasks.csv generated\n",
      "task_file:case_heavy_2000_tasks.csv generated\n",
      "采样统计: 总任务数 3000, 单卡任务 2790 (93.0%), 多卡任务 210 (7.0%)\n",
      "采样统计: 总任务数 3000, 单卡任务 2700 (90.0%), 多卡任务 300 (10.0%)\n",
      "采样统计: 总任务数 3000, 单卡任务 1500 (50.0%), 多卡任务 1500 (50.0%)\n",
      "random task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      2790\n",
      "1       2.0        42\n",
      "2       3.0        13\n",
      "3       4.0        37\n",
      "4       5.0        49\n",
      "5       6.0        16\n",
      "6       7.0         4\n",
      "7       8.0        49\n",
      "light task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      2700\n",
      "1       2.0        55\n",
      "2       3.0         8\n",
      "3       4.0        61\n",
      "4       5.0        62\n",
      "5       6.0        24\n",
      "6       7.0         1\n",
      "7       8.0        89\n",
      "heavy task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      1500\n",
      "1       2.0       293\n",
      "2       3.0        56\n",
      "3       4.0       356\n",
      "4       5.0       268\n",
      "5       6.0       102\n",
      "6       7.0         4\n",
      "7       8.0       421\n",
      "task_file:case_random_3000_tasks.csv generated\n",
      "task_file:case_light_3000_tasks.csv generated\n",
      "task_file:case_heavy_3000_tasks.csv generated\n",
      "采样统计: 总任务数 4000, 单卡任务 3703 (92.6%), 多卡任务 297 (7.4%)\n",
      "采样统计: 总任务数 4000, 单卡任务 3600 (90.0%), 多卡任务 400 (10.0%)\n",
      "采样统计: 总任务数 4000, 单卡任务 2000 (50.0%), 多卡任务 2000 (50.0%)\n",
      "random task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      3703\n",
      "1       2.0        58\n",
      "2       3.0        17\n",
      "3       4.0        72\n",
      "4       5.0        52\n",
      "5       6.0        14\n",
      "6       8.0        84\n",
      "light task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      3600\n",
      "1       2.0        97\n",
      "2       3.0        21\n",
      "3       4.0        89\n",
      "4       5.0        77\n",
      "5       6.0        27\n",
      "6       7.0         2\n",
      "7       8.0        87\n",
      "heavy task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      2000\n",
      "1       2.0       412\n",
      "2       3.0        81\n",
      "3       4.0       467\n",
      "4       5.0       385\n",
      "5       6.0       135\n",
      "6       7.0        11\n",
      "7       8.0       509\n",
      "task_file:case_random_4000_tasks.csv generated\n",
      "task_file:case_light_4000_tasks.csv generated\n",
      "task_file:case_heavy_4000_tasks.csv generated\n",
      "采样统计: 总任务数 5000, 单卡任务 4631 (92.6%), 多卡任务 369 (7.4%)\n",
      "采样统计: 总任务数 5000, 单卡任务 4500 (90.0%), 多卡任务 500 (10.0%)\n",
      "采样统计: 总任务数 5000, 单卡任务 2500 (50.0%), 多卡任务 2500 (50.0%)\n",
      "random task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      4631\n",
      "1       2.0        80\n",
      "2       3.0        17\n",
      "3       4.0        78\n",
      "4       5.0        79\n",
      "5       6.0        21\n",
      "6       7.0         2\n",
      "7       8.0        92\n",
      "light task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      4500\n",
      "1       2.0        97\n",
      "2       3.0        16\n",
      "3       4.0       129\n",
      "4       5.0       103\n",
      "5       6.0        31\n",
      "6       7.0         3\n",
      "7       8.0       121\n",
      "heavy task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      2500\n",
      "1       2.0       510\n",
      "2       3.0        97\n",
      "3       4.0       600\n",
      "4       5.0       476\n",
      "5       6.0       173\n",
      "6       7.0        11\n",
      "7       8.0       633\n",
      "task_file:case_random_5000_tasks.csv generated\n",
      "task_file:case_light_5000_tasks.csv generated\n",
      "task_file:case_heavy_5000_tasks.csv generated\n",
      "采样统计: 总任务数 6000, 单卡任务 5560 (92.7%), 多卡任务 440 (7.3%)\n",
      "采样统计: 总任务数 6000, 单卡任务 5400 (90.0%), 多卡任务 600 (10.0%)\n",
      "采样统计: 总任务数 6000, 单卡任务 3266 (54.4%), 多卡任务 2734 (45.6%)\n",
      "random task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      5560\n",
      "1       2.0        92\n",
      "2       3.0        17\n",
      "3       4.0       100\n",
      "4       5.0        82\n",
      "5       6.0        32\n",
      "6       8.0       117\n",
      "light task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      5400\n",
      "1       2.0       104\n",
      "2       3.0        28\n",
      "3       4.0       146\n",
      "4       5.0       122\n",
      "5       6.0        46\n",
      "6       7.0         2\n",
      "7       8.0       152\n",
      "heavy task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      3266\n",
      "1       2.0       556\n",
      "2       3.0       108\n",
      "3       4.0       653\n",
      "4       5.0       520\n",
      "5       6.0       192\n",
      "6       7.0        12\n",
      "7       8.0       693\n",
      "task_file:case_random_6000_tasks.csv generated\n",
      "task_file:case_light_6000_tasks.csv generated\n",
      "task_file:case_heavy_6000_tasks.csv generated\n",
      "采样统计: 总任务数 7000, 单卡任务 6507 (93.0%), 多卡任务 493 (7.0%)\n",
      "采样统计: 总任务数 7000, 单卡任务 6300 (90.0%), 多卡任务 700 (10.0%)\n",
      "采样统计: 总任务数 7000, 单卡任务 4266 (60.9%), 多卡任务 2734 (39.1%)\n",
      "random task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      6507\n",
      "1       2.0       110\n",
      "2       3.0        19\n",
      "3       4.0       128\n",
      "4       5.0        93\n",
      "5       6.0        37\n",
      "6       7.0         1\n",
      "7       8.0       105\n",
      "light task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      6300\n",
      "1       2.0       133\n",
      "2       3.0        27\n",
      "3       4.0       169\n",
      "4       5.0       151\n",
      "5       6.0        37\n",
      "6       7.0         3\n",
      "7       8.0       180\n",
      "heavy task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      4266\n",
      "1       2.0       556\n",
      "2       3.0       108\n",
      "3       4.0       653\n",
      "4       5.0       520\n",
      "5       6.0       192\n",
      "6       7.0        12\n",
      "7       8.0       693\n",
      "task_file:case_random_7000_tasks.csv generated\n",
      "task_file:case_light_7000_tasks.csv generated\n",
      "task_file:case_heavy_7000_tasks.csv generated\n",
      "采样统计: 总任务数 8000, 单卡任务 7443 (93.0%), 多卡任务 557 (7.0%)\n",
      "采样统计: 总任务数 8000, 单卡任务 7200 (90.0%), 多卡任务 800 (10.0%)\n",
      "采样统计: 总任务数 8000, 单卡任务 5266 (65.8%), 多卡任务 2734 (34.2%)\n",
      "random task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      7443\n",
      "1       2.0       118\n",
      "2       3.0        18\n",
      "3       4.0       148\n",
      "4       5.0        89\n",
      "5       6.0        35\n",
      "6       7.0         2\n",
      "7       8.0       147\n",
      "light task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      7200\n",
      "1       2.0       163\n",
      "2       3.0        36\n",
      "3       4.0       189\n",
      "4       5.0       139\n",
      "5       6.0        59\n",
      "6       7.0         3\n",
      "7       8.0       211\n",
      "heavy task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      5266\n",
      "1       2.0       556\n",
      "2       3.0       108\n",
      "3       4.0       653\n",
      "4       5.0       520\n",
      "5       6.0       192\n",
      "6       7.0        12\n",
      "7       8.0       693\n",
      "task_file:case_random_8000_tasks.csv generated\n",
      "task_file:case_light_8000_tasks.csv generated\n",
      "task_file:case_heavy_8000_tasks.csv generated\n",
      "采样统计: 总任务数 9000, 单卡任务 8387 (93.2%), 多卡任务 613 (6.8%)\n",
      "采样统计: 总任务数 9000, 单卡任务 8100 (90.0%), 多卡任务 900 (10.0%)\n",
      "采样统计: 总任务数 9000, 单卡任务 6266 (69.6%), 多卡任务 2734 (30.4%)\n",
      "random task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      8387\n",
      "1       2.0       128\n",
      "2       3.0        24\n",
      "3       4.0       134\n",
      "4       5.0       115\n",
      "5       6.0        39\n",
      "6       7.0         3\n",
      "7       8.0       170\n",
      "light task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      8100\n",
      "1       2.0       196\n",
      "2       3.0        40\n",
      "3       4.0       215\n",
      "4       5.0       147\n",
      "5       6.0        61\n",
      "6       7.0         2\n",
      "7       8.0       239\n",
      "heavy task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      6266\n",
      "1       2.0       556\n",
      "2       3.0       108\n",
      "3       4.0       653\n",
      "4       5.0       520\n",
      "5       6.0       192\n",
      "6       7.0        12\n",
      "7       8.0       693\n",
      "task_file:case_random_9000_tasks.csv generated\n",
      "task_file:case_light_9000_tasks.csv generated\n",
      "task_file:case_heavy_9000_tasks.csv generated\n",
      "采样统计: 总任务数 10000, 单卡任务 9274 (92.7%), 多卡任务 726 (7.3%)\n",
      "采样统计: 总任务数 10000, 单卡任务 9000 (90.0%), 多卡任务 1000 (10.0%)\n",
      "采样统计: 总任务数 10000, 单卡任务 7266 (72.7%), 多卡任务 2734 (27.3%)\n",
      "random task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      9274\n",
      "1       2.0       150\n",
      "2       3.0        30\n",
      "3       4.0       183\n",
      "4       5.0       128\n",
      "5       6.0        39\n",
      "6       7.0         3\n",
      "7       8.0       193\n",
      "light task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      9000\n",
      "1       2.0       200\n",
      "2       3.0        48\n",
      "3       4.0       233\n",
      "4       5.0       179\n",
      "5       6.0        83\n",
      "6       7.0         2\n",
      "7       8.0       255\n",
      "heavy task num:\n",
      "   inst_num  task_num\n",
      "0       1.0      7266\n",
      "1       2.0       556\n",
      "2       3.0       108\n",
      "3       4.0       653\n",
      "4       5.0       520\n",
      "5       6.0       192\n",
      "6       7.0        12\n",
      "7       8.0       693\n",
      "task_file:case_random_10000_tasks.csv generated\n",
      "task_file:case_light_10000_tasks.csv generated\n",
      "task_file:case_heavy_10000_tasks.csv generated\n"
     ]
    }
   ],
   "source": [
    "def generate_task_config(jobs_count: int):\n",
    "    \"\"\"生成任务配置\"\"\"\n",
    "    task_df = read_csv_with_header(os.path.join(DATA_DIR, \"pai_task_table.csv\"))\n",
    "    valid_task_df = preprocess_training_data(task_df)\n",
    "    random_task_df = sample_tasks_random(valid_task_df, jobs_count)\n",
    "    random_task_wrap_runtimes_df = gen_task_runtimes(random_task_df)\n",
    "\n",
    "    light_task_df = sample_tasks_with_ratio(valid_task_df, jobs_count, 0.1)\n",
    "    light_task_wrap_runtimes_df = gen_task_runtimes(light_task_df)\n",
    "\n",
    "    heavy_task_df = sample_tasks_with_ratio(valid_task_df, jobs_count, 0.5)\n",
    "    heavy_task_wrap_runtimes_df = gen_task_runtimes(heavy_task_df)\n",
    "\n",
    "    # 输出不同实例数的Task个数\n",
    "    task_num_df = random_task_wrap_runtimes_df.groupby('inst_num').size().reset_index(name='task_num')\n",
    "    print(\"random task num:\")\n",
    "    print(task_num_df)\n",
    "\n",
    "    task_num_df = light_task_wrap_runtimes_df.groupby('inst_num').size().reset_index(name='task_num')\n",
    "    print(\"light task num:\")\n",
    "    print(task_num_df)\n",
    "\n",
    "    task_num_df = heavy_task_wrap_runtimes_df.groupby('inst_num').size().reset_index(name='task_num')\n",
    "    print(\"heavy task num:\")\n",
    "    print(task_num_df)\n",
    "    # 统计信息\n",
    "    to_csv(random_task_wrap_runtimes_df, f\"case_random_{jobs_count}_tasks.csv\")\n",
    "    print(f\"task_file:{f'case_random_{jobs_count}_tasks.csv'} generated\")\n",
    "\n",
    "    to_csv(light_task_wrap_runtimes_df, f\"case_light_{jobs_count}_tasks.csv\")\n",
    "    print(f\"task_file:{f'case_light_{jobs_count}_tasks.csv'} generated\")\n",
    "\n",
    "    to_csv(heavy_task_wrap_runtimes_df, f\"case_heavy_{jobs_count}_tasks.csv\")\n",
    "    print(f\"task_file:{f'case_heavy_{jobs_count}_tasks.csv'} generated\")\n",
    "\n",
    "def main():\n",
    "    jobs_count_list = [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "\n",
    "    for jobs_count in jobs_count_list:\n",
    "        generate_task_config(jobs_count)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ced-train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
